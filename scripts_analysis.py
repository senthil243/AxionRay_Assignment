# -*- coding: utf-8 -*-
"""scripts/analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11hq1nU4yLqfRVZyQfmKHd8p3DOtCm0vZ
"""

import pandas as pd
import matplotlib.pyplot as plt

task_df = pd.read_csv('DA -Task 2..xlsx - Sheet1.csv')

task_df.to_csv('DA -Task 2..xlsx - Sheet1.csv')

task_df.head()

task_df.dtypes

"""**Column-Wise Analysis**"""

print(task_df.info())

unique_values = task_df.nunique()
print("\nUnique Values per Column:\n", unique_values)


print("\nNumerical Columns Summary:\n", task_df.describe())


categorical_cols = task_df.select_dtypes(include=['object']).columns
print("\nCategorical Columns Summary:\n", task_df[categorical_cols].describe())


missing_values = task_df.isnull().sum()
print("\nMissing Values per Column:\n", missing_values)

"""Data CLeaning

Handling Missing Values
"""

task_df = task_df.dropna(axis=1, thresh=len(task_df) * 0.3)

task_df.fillna({col: 'Unknown' for col in task_df.select_dtypes(include=['object']).columns}, inplace=True)
task_df.fillna(task_df.median(numeric_only=True), inplace=True)

print("Remaining Missing Values:", task_df.isnull().sum().sum())

"""Address Inconsistencies in Categorical Columns"""

for col in categorical_cols:
    task_df[col] = task_df[col].str.strip().str.lower().str.title()

# Check unique values in key categorical columns
for col in ['STATE', 'PLATFORM', 'BODY_STYLE']:
    print(f"\nUnique values in {col}:\n", task_df[col].unique())

"""Convert Numerical Columns & Remove Outliers"""

import numpy as np

cost_columns = ['REPORTING_COST', 'TOTALCOST', 'LBRCOST']
for col in cost_columns:
    task_df[col] = pd.to_numeric(task_df[col].astype(str).str.replace('[^\d.]', '', regex=True), errors='coerce')

for col in cost_columns:
    Q1 = task_df[col].quantile(0.25)
    Q3 = task_df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    task_df = task_df[(task_df[col] >= lower_bound) & (task_df[col] <= upper_bound)]


print("\nNumerical Columns Summary:\n", task_df.describe())

"""top 5 critical columns

Distribution of Repair Costs
"""

import seaborn as sns
sns.set_style("whitegrid")
plt.figure(figsize=(8, 5))
sns.histplot(task_df['TOTALCOST'], bins=20, kde=True, color='blue')
plt.title("Distribution of Repair Costs")
plt.xlabel("Total Cost ($)")
plt.ylabel("Frequency")
plt.show()

"""Repair Age vs Total Cost(Scatter Plot)"""

plt.figure(figsize=(8, 5))
sns.scatterplot(x=task_df['REPAIR_AGE'], y=task_df['TOTALCOST'], alpha=0.7)
plt.title("Repair Age vs Total Cost")
plt.xlabel("Vehicle Age at Repair (Years)")
plt.ylabel("Total Cost ($)")
plt.show()

"""Most Common Complaints (Bar Chart)"""

plt.figure(figsize=(10, 5))
sns.countplot(y=task_df['COMPLAINT_CD'], order=task_df['COMPLAINT_CD'].value_counts().index[:10], palette='coolwarm')
plt.title("Most Common Complaint Codes")
plt.xlabel("Frequency")
plt.ylabel("Complaint Code")
plt.show()

print(task_df.info())

from collections import Counter
import re

# Combine relevant text columns
text_data = " ".join(task_df[["CUSTOMER_VERBATIM", "CORRECTION_VERBATIM", "CAUSAL_PART_NM", "GLOBAL_LABOR_CODE_DESCRIPTION"]].fillna("").agg(" ".join, axis=1))

# Clean and split words
words = re.findall(r'\b\w+\b', text_data.lower())

# Count word occurrences
word_counts = Counter(words)

# Get the top 20 most common words (tags)
tags = [word for word, count in word_counts.most_common(20)]
print(tags)